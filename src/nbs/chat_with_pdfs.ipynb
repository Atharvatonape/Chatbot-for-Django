{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "573eea24-e444-4b26-a1fb-398fc1205cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.10.59-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core==0.10.59 (from llama-index)\n",
      "  Downloading llama_index_core-0.10.59-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.27 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.1.27-py3-none-any.whl.metadata (610 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.1.32-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index) (6.0.1)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.59->llama-index)\n",
      "  Downloading SQLAlchemy-2.0.31-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core==0.10.59->llama-index)\n",
      "  Downloading aiohttp-3.10.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Collecting dataclasses-json (from llama-index-core==0.10.59->llama-index)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.59->llama-index)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.59->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: httpx in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core==0.10.59->llama-index)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting numpy<2.0.0 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index) (1.38.0)\n",
      "Collecting pandas (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached pillow-10.4.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core==0.10.59->llama-index)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core==0.10.59->llama-index)\n",
      "  Downloading tiktoken-0.7.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index) (4.12.2)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core==0.10.59->llama-index)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core==0.10.59->llama-index)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index)\n",
      "  Downloading llama_cloud-0.0.11-py3-none-any.whl.metadata (751 bytes)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index)\n",
      "  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index)\n",
      "  Downloading aiohappyeyeballs-2.3.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index) (24.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index)\n",
      "  Downloading multidict-6.0.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index)\n",
      "  Downloading yarl-1.9.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (2.8.2)\n",
      "Requirement already satisfied: anyio in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from httpx->llama-index-core==0.10.59->llama-index) (4.4.0)\n",
      "Requirement already satisfied: certifi in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from httpx->llama-index-core==0.10.59->llama-index) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from httpx->llama-index-core==0.10.59->llama-index) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from httpx->llama-index-core==0.10.59->llama-index) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from httpx->llama-index-core==0.10.59->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.59->llama-index) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.59->llama-index) (8.1.7)\n",
      "Collecting joblib (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.59->llama-index)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.59->llama-index)\n",
      "  Downloading regex-2024.7.24-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core==0.10.59->llama-index) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core==0.10.59->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core==0.10.59->llama-index) (2.2.2)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.59->llama-index)\n",
      "  Downloading greenlet-3.0.3-cp312-cp312-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.59->llama-index)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core==0.10.59->llama-index)\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from pandas->llama-index-core==0.10.59->llama-index) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->llama-index-core==0.10.59->llama-index)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from pandas->llama-index-core==0.10.59->llama-index) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.59->llama-index) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/A200298519/Desktop/MVP/django-chatbot/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.59->llama-index) (1.16.0)\n",
      "Downloading llama_index-0.10.59-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_core-0.10.59-py3-none-any.whl (15.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl (9.5 kB)\n",
      "Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_llms_openai-0.1.27-py3-none-any.whl (11 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.1.32-py3-none-any.whl (38 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
      "Downloading aiohttp-3.10.0-cp312-cp312-macosx_11_0_arm64.whl (385 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Downloading llama_cloud-0.0.11-py3-none-any.whl (154 kB)\n",
      "Downloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "Using cached pillow-10.4.0-cp312-cp312-macosx_11_0_arm64.whl (3.4 MB)\n",
      "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "Downloading SQLAlchemy-2.0.31-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.7.0-cp312-cp312-macosx_11_0_arm64.whl (906 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.7/906.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading wrapt-1.16.0-cp312-cp312-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Downloading aiohappyeyeballs-2.3.4-py3-none-any.whl (12 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-macosx_11_0_arm64.whl (51 kB)\n",
      "Downloading greenlet-3.0.3-cp312-cp312-macosx_11_0_universal2.whl (273 kB)\n",
      "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "Downloading multidict-6.0.5-cp312-cp312-macosx_11_0_arm64.whl (29 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Downloading regex-2024.7.24-cp312-cp312-macosx_11_0_arm64.whl (279 kB)\n",
      "Downloading yarl-1.9.4-cp312-cp312-macosx_11_0_arm64.whl (79 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: striprtf, pytz, dirtyjson, wrapt, tenacity, SQLAlchemy, regex, pypdf, pillow, numpy, networkx, mypy-extensions, multidict, marshmallow, joblib, greenlet, fsspec, frozenlist, aiohappyeyeballs, yarl, typing-inspect, tiktoken, pandas, nltk, deprecated, aiosignal, llama-cloud, dataclasses-json, aiohttp, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "Successfully installed SQLAlchemy-2.0.31 aiohappyeyeballs-2.3.4 aiohttp-3.10.0 aiosignal-1.3.1 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 frozenlist-1.4.1 fsspec-2024.6.1 greenlet-3.0.3 joblib-1.4.2 llama-cloud-0.0.11 llama-index-0.10.59 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.59 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.2.7 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.27 llama-index-multi-modal-llms-openai-0.1.8 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.32 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 marshmallow-3.21.3 multidict-6.0.5 mypy-extensions-1.0.0 networkx-3.3 nltk-3.8.1 numpy-1.26.4 pandas-2.2.2 pillow-10.4.0 pypdf-4.3.1 pytz-2024.1 regex-2024.7.24 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0 wrapt-1.16.0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7fc932f-5528-48f7-949d-c1f24995d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup\n",
    "setup.init_django()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3269596-4e8b-4483-8ad1-0fea23bdfa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/A200298519/Desktop/MVP/django-chatbot/src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "564c3b9b-bc0d-4c26-8159-1cc14f6feb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers\n",
    "DJANGO_PDF_PATH = helpers.config('DJANGO_PDF_PATH',default=None, cast=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73a0f980-c7fd-4194-8684-8138635a4aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "django_pdf = \"data/django.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77029ccc-9050-46a9-9a01-1f280bb8a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43ae9ded-7d62-43a5-b523-c9c22735d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(input_files=[django_pdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab702033-cb9f-4336-81ba-c5fafe7833c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ad0b6eb-a92f-4863-8c6b-5bd919ce2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = helpers.config(\"OPEANAI_API_KEY\", default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fca9750-912a-4d46-a6a2-4bd47d356e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8dbcb821-9d1d-4311-8020-e068371e5a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7584d1b3-d044-4192-a0e6-4820fd868857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals in Django are a way for different parts of an application to communicate with each other in a decoupled manner. They allow certain senders to notify a set of receivers when some action or event occurs. This mechanism helps in keeping different components of the application loosely coupled, enabling better organization and separation of concerns. Signals are used to trigger specific actions or functions based on events happening within the application without directly linking the sender and receiver components.\n"
     ]
    }
   ],
   "source": [
    "r =  query_engine.query(\"Explain to me signals concept\")\n",
    "print(r.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f7a89-b9eb-4448-957a-51945610bc68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
